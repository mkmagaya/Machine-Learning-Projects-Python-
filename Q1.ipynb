{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkmagaya/Machine-Learning-Projects-Python-/blob/master/Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Es2TzVFpJEG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string \n",
        "import re\n",
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Noc-QyxDmoJU",
        "outputId": "c834a606-c34b-49ab-f34e-c890213cb755"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-da-lLfrGb6"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/R181599G/spam_or_not_spam.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3tYC9KaTTH9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzjirdXXtRdP",
        "outputId": "175c9ed8-d422-4a65-ac9c-8941c764be04"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   email   2999 non-null   object\n",
            " 1   label   3000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "8GLeyfPCts9F",
        "outputId": "105e5652-f846-4324-8801-3f38bfc7db5b"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>email</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>man threatens explosion in moscow thursday aug...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>klez the virus that won t die already the most...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               email  label\n",
              "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
              "1  martin a posted tassos papadopoulos the greek ...      0\n",
              "2  man threatens explosion in moscow thursday aug...      0\n",
              "3  klez the virus that won t die already the most...      0\n",
              "4   in adding cream to spaghetti carbonara which ...      0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA35ZV_fuJLV"
      },
      "source": [
        "dataset.loc[dataset.label == 'Not Spam']=0\n",
        "dataset.loc[dataset.label == 'Spam']=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpiyYet4uld5"
      },
      "source": [
        "#split data into x and y variables\n",
        "X = dataset['email']\n",
        "y = dataset['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5kZdYusLUJ"
      },
      "source": [
        "#splitting data into training and test sets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DakAcmy3s7v7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYtpuiC0v7it"
      },
      "source": [
        "Building a vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d73Mp00v17P"
      },
      "source": [
        "import string\n",
        "import re\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAZ2gWCkzMfy",
        "outputId": "2fd2abb7-d52e-4aba-c870-c444851dbe36"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDgmxPQNwhu3"
      },
      "source": [
        "#Load text data\n",
        "def load_doc(filename):\n",
        "# open the file as read only\n",
        "  file = open(filename, 'r' )\n",
        "# read all text\n",
        "  text = file.read()\n",
        "# close the file\n",
        "  file.close()\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uDR0A-yxNdz"
      },
      "source": [
        "from os import listdir\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVVu0fscyeWH"
      },
      "source": [
        "def process_docs(directory):\n",
        "  for filename in listdir(directory):\n",
        "    if not filename.endswith(\".txt\"):\n",
        "      next\n",
        "    path = directory + '/' + filename\n",
        "    doc = load_doc(path)\n",
        "    # print( ' Loaded %s ' % filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRzJSR-Dyl3D"
      },
      "source": [
        "#Cleaning the doc\n",
        "def clean_doc(doc):\n",
        "  tokens = doc.split()\n",
        "  re_punc = re.compile( '[%s]' % re.escape(string.punctuation))\n",
        "  tokens = [re_punc.sub( '' , w) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  stop_words = set(stopwords.words( 'english' ))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  tokens = [word for word in tokens if len(word) > 1]\n",
        "  return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "545IZwteynSs",
        "outputId": "7d52e47d-c8c6-4f4d-aad9-5db5dde700ed"
      },
      "source": [
        "#add a email review to a vocabulary\n",
        "filename ='/content/drive/MyDrive/Colab Notebooks/exam/datasets/spam_or_not_spam.csv'\n",
        "text = load_doc(filename)\n",
        "tokens = clean_doc(text)\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mh4b9I8ziKb"
      },
      "source": [
        "def add_doc_to_vocab(filename, vocab):\n",
        "# load doc\n",
        "  doc = load_doc(filename)\n",
        "# clean doc\n",
        "  tokens = clean_doc(doc)\n",
        "# update counts\n",
        "  vocab.update(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSuI-q7O0Od9"
      },
      "source": [
        "# load all docs in a directory\n",
        "def process_docs(directory, vocab):\n",
        "# walk through all files in the folder\n",
        "  for filename in listdir(directory):\n",
        "# skip files that do not have the right extension\n",
        "    if not filename.endswith(\".txt\"):\n",
        "      next\n",
        "# create the full path of the file to open\n",
        "    path = directory + '/' + filename\n",
        "# add doc to vocab\n",
        "    add_doc_to_vocab(path, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTGLgt_l0jar",
        "outputId": "710174b1-a756-41ef-8f9b-1a75fcf90023"
      },
      "source": [
        "\n",
        "import string\n",
        "import re\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "# define vocab\n",
        "vocab = Counter()\n",
        "process_docs( '/content/drive/MyDrive/Colab Notebooks/exam/datasets/spam_or_not_spam.csv' , vocab)\n",
        "\n",
        "# print the size of the vocab\n",
        "print(len(vocab))\n",
        "# print the top words in the vocab\n",
        "print(vocab.most_common(50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33648\n",
            "[('NUMBER', 33465), ('URL', 7974), ('list', 2171), ('one', 1674), ('get', 1590), ('people', 1315), ('time', 1290), ('use', 1255), ('would', 1254), ('like', 1248), ('new', 1200), ('free', 1180), ('email', 1168), ('mail', 1039), ('wrote', 921), ('also', 914), ('rpm', 896), ('make', 879), ('date', 871), ('mailing', 871), ('message', 854), ('world', 806), ('said', 803), ('us', 798), ('hyperlink', 786), ('spamassassin', 754), ('way', 728), ('money', 722), ('first', 719), ('users', 719), ('could', 718), ('url', 708), ('information', 707), ('think', 699), ('work', 694), ('even', 685), ('spam', 654), ('know', 654), ('want', 641), ('see', 634), ('please', 630), ('may', 611), ('exmh', 593), ('much', 581), ('using', 576), ('well', 576), ('business', 569), ('many', 567), ('linux', 556), ('need', 556)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfLJLq9I0xDs",
        "outputId": "addc31d2-3ff1-4d0a-aada-54188b9b0aff"
      },
      "source": [
        "min_occurance = 5\n",
        "tokens = [k for k,c in vocab.items() if c >= min_occurance]\n",
        "print(len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtajTQ3e051p"
      },
      "source": [
        "def save_list(lines, filename):\n",
        "  data = '\\n' .join(lines)\n",
        "  file = open(filename, 'w' )\n",
        "  file.write(data)\n",
        "  file.close()\n",
        "# save tokens to a vocabulary file\n",
        "save_list(tokens, '/content/drive/MyDrive/Colab Notebooks/exam/datasets/spam_or_not_spam.csv' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trpn13OO1HeQ"
      },
      "source": [
        "vocab_filename = '/content/drive/MyDrive/Colab Notebooks/exam/datasets/spam_or_not_spam.csv'\n",
        "vocab = load_doc(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLcELqToY-jx"
      },
      "source": [
        "def doc_to_line(filename, vocab):\n",
        "# load the doc\n",
        "  doc = load_doc(filename)\n",
        "# clean doc\n",
        "  tokens = clean_doc(doc)\n",
        "# filter by vocab\n",
        "  tokens = [w for w in tokens if w in vocab]\n",
        "  return ' '.join(tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVacZd0JZFhF"
      },
      "source": [
        "def process_docs(directory, vocab):\n",
        "  lines = list()\n",
        "  for filename in listdir(directory):\n",
        "    if not filename.endswith(\".txt\"):\n",
        "      next\n",
        "    path = directory + '/' + filename\n",
        "    line = doc_to_line(path, vocab)\n",
        "    lines.append(line)\n",
        "  return lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Q8T1-yPiC2"
      },
      "source": [
        "spam = process_docs( 'question1' , vocab)\n",
        "save_list(spam, 'spamemails.txt' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhmU2vvV3Cd6"
      },
      "source": [
        "Converting to word embedding vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_njTYVfL3Ev0"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb33Jprp51hM",
        "outputId": "8434c370-214e-4f5e-8d69-c003473189ba"
      },
      "source": [
        "email = 'vocab.txt'\n",
        "model = Word2Vec(email, min_count=1)\n",
        "\n",
        "print(model)\n",
        "\n",
        "words = list(model.wv.vocab)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=34, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl29m_FI6jZZ",
        "outputId": "1274411f-ad6c-4aa0-cc5c-40a5cd7ee21b"
      },
      "source": [
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/', 'c', 'o', 'n', 't', 'e', 'd', 'r', 'i', 'v', 'M', 'y', ' ', 'D', 'C', 'l', 'a', 'b', 'N', 'k', 's', 'E', 'x', 'm', 'R', '1', '8', '5', '9', '3', 'L', 'q', 'u', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRFuPUzC7Vb1",
        "outputId": "54d6a68b-67af-4f96-ca37-4b89abbc7f3e"
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "input_file = 'vocab.txt'\n",
        "word2vec_output_file = 'vocab.txt.word2vec'\n",
        "glove2word2vec(input_file, word2vec_output_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9297, 0)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0On91CQ84SF"
      },
      "source": [
        "#Building LSTM Model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz-OIDNa872d"
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfQzymYu_O7s"
      },
      "source": [
        "def save_doc(lines, filename):\n",
        "  data = '\\n' .join(lines)\n",
        "  file = open(filename, 'w' )\n",
        "  file.write(data)\n",
        "  file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oZXrNQ3eU8R",
        "outputId": "31d3a902-e549-4949-f10f-e152588e6b14"
      },
      "source": [
        "# organize into sequences of tokens\n",
        "length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "  # select sequence of tokens\n",
        "  seq = tokens[i-length:i]\n",
        "\n",
        "  # convert into a line\n",
        "  line = ' '.join(seq)\n",
        "\n",
        "  # store\n",
        "  sequences.append(line)\n",
        "\n",
        "print(f'Total Sequences: {len(sequences)}')\n",
        "# save sequences to file\n",
        "out_filename = 'vocab.txt'\n",
        "save_doc(sequences, out_filename)\n",
        "\n",
        "# load\n",
        "in_filename = 'vocab.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Sequences: 9246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anxYLs4U9TwE",
        "outputId": "47007852-3109-49c7-b916-cc4d05f1baf2"
      },
      "source": [
        "# load\n",
        "in_filename = 'vocab.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split( '\\n' )\n",
        "lines[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['date wed NUMBER aug chris garrigues cwg dated deepeddy com message id tmda vircio reproduce error like every time without fail debug log pick happening exec inbox list lbrace subject ftp rbrace sequence mercury hit marking hits syntax expression int note run command hand delta comes obviously version nmh using compiled',\n",
              " 'wed NUMBER aug chris garrigues cwg dated deepeddy com message id tmda vircio reproduce error like every time without fail debug log pick happening exec inbox list lbrace subject ftp rbrace sequence mercury hit marking hits syntax expression int note run command hand delta comes obviously version nmh using compiled URL',\n",
              " 'NUMBER aug chris garrigues cwg dated deepeddy com message id tmda vircio reproduce error like every time without fail debug log pick happening exec inbox list lbrace subject ftp rbrace sequence mercury hit marking hits syntax expression int note run command hand delta comes obviously version nmh using compiled URL sun',\n",
              " 'aug chris garrigues cwg dated deepeddy com message id tmda vircio reproduce error like every time without fail debug log pick happening exec inbox list lbrace subject ftp rbrace sequence mercury hit marking hits syntax expression int note run command hand delta comes obviously version nmh using compiled URL sun relevant',\n",
              " 'chris garrigues cwg dated deepeddy com message id tmda vircio reproduce error like every time without fail debug log pick happening exec inbox list lbrace subject ftp rbrace sequence mercury hit marking hits syntax expression int note run command hand delta comes obviously version nmh using compiled URL sun relevant part']"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ElYUto9ElW",
        "outputId": "e7c65404-ab97-4266-a3d4-d985a9281af0"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "print(sequences[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[9292, 9290, 3, 9287, 9285, 9283, 9281, 9279, 9277, 9275, 9273, 9271, 9269, 9267, 9265, 9263, 9261, 9259, 9257, 9255, 9253, 9251, 9249, 9247, 9245, 9243, 9241, 9239, 9237, 9235, 9233, 9231, 9229, 9227, 9225, 9223, 9221, 9219, 9217, 9215, 9213, 9211, 9209, 9207, 9205, 9203, 9201, 9199, 9197, 9195, 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlrcx-Q39qui"
      },
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_AYbtG_91aZ"
      },
      "source": [
        "# separate into input and output\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMG3pFU396c5"
      },
      "source": [
        "def define_model(vocab_size, seq_length):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "  model.add(LSTM(100, return_sequences=True))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(100, activation= 'relu' ))\n",
        "  model.add(Dense(vocab_size, activation= 'softmax'))\n",
        "  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  plot_model(model, to_file= '/model.png' , show_shapes=True)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjG-24i9-GxQ",
        "outputId": "f4551eca-bb6f-47be-a99c-2884986a561c"
      },
      "source": [
        "model = define_model(vocab_size, seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 50)            464700    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 9294)              938694    \n",
            "=================================================================\n",
            "Total params: 1,554,294\n",
            "Trainable params: 1,554,294\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KIMzGxi-OLc",
        "outputId": "49eb8e50-206f-417a-ff53-90bd98f35876"
      },
      "source": [
        "model.fit(X, y, batch_size=10, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "925/925 [==============================] - 85s 88ms/step - loss: 9.2938 - accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "925/925 [==============================] - 80s 86ms/step - loss: 9.1741 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc968f56110>"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHovBtZEAWY0"
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "with open('tokenizer.pkl' , 'wb') as token_sv:\n",
        "  dump(tokenizer, token_sv) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1tMM19cAktH",
        "outputId": "cea364c3-ac38-4433-8f8a-34e1262f8287"
      },
      "source": [
        "#evaluate the model\n",
        "_, acc = model.evaluate(X, y, verbose=2)\n",
        "print(f'Train Accuracy: {(acc*100)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "289/289 - 11s - loss: 9.1572 - accuracy: 1.0815e-04\n",
            "Train Accuracy: 0.010815487621584907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCxAVhw-Aqu-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}